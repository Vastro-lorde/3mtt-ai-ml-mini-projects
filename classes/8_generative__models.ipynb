{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd637659",
      "metadata": {
        "id": "bd637659"
      },
      "source": [
        "ðŸŽ¥ Recommended Video: [What are GANs](https://www.youtube.com/watch?v=TpMIssRdhco)\n",
        "\n",
        "ðŸŽ¥ Recommended Video: [What are Autoencoders](https://www.youtube.com/watch?v=qiUEgSCyY5o)\n",
        "\n",
        "ðŸŽ¥ Recommended Video: [Diffusion models explained in 4-difficulty levels](https://www.youtube.com/watch?v=yTAMrHVG1ew)\n",
        "\n",
        "## **8. Generative Models**\n",
        "\n",
        "### **8.1 What are Generative Models?**\n",
        "Generative models are a class of machine learning models designed to generate new data samples that resemble a given dataset. They learn the underlying distribution of the data and can create realistic images, text, audio, and more.\n",
        "\n",
        "#### **Key Applications of Generative Models**:\n",
        "- **Image Synthesis**: Creating realistic images (e.g., faces, landscapes).\n",
        "- **Data Augmentation**: Generating additional training data.\n",
        "- **Style Transfer**: Transforming images into different artistic styles.\n",
        "- **Super-Resolution**: Enhancing the resolution of images.\n",
        "\n",
        "---\n",
        "\n",
        "### **8.2 Types of Generative Models**\n",
        "There are several types of generative models, each with its own strengths and use cases:\n",
        "\n",
        "#### **8.2.1 Generative Adversarial Networks (GANs)**\n",
        "- Consist of two neural networks: a **generator** and a **discriminator**.\n",
        "- The generator creates fake data, while the discriminator tries to distinguish between real and fake data.\n",
        "- They are trained simultaneously in a competitive manner.\n",
        "\n",
        "#### **8.2.2 Variational Autoencoders (VAEs)**\n",
        "- Encode input data into a latent space and decode it back to the original data.\n",
        "- Focus on learning a probabilistic representation of the data.\n",
        "- Useful for generating diverse and smooth interpolations between data points.\n",
        "\n",
        "#### **8.2.3 Diffusion Models**\n",
        "- Gradually add noise to data and then learn to reverse the process to generate new samples.\n",
        "- Known for producing high-quality images.\n",
        "\n",
        "---\n",
        "\n",
        "### **8.3 Code Example: Building a GAN**\n",
        "Letâ€™s build a simple GAN using TensorFlow/Keras to generate handwritten digits (MNIST dataset).\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the generator\n",
        "def build_generator(latent_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(28 * 28, activation='tanh'),  # Output layer\n",
        "        layers.Reshape((28, 28, 1))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the discriminator\n",
        "def build_discriminator():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # Output layer\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and compile the GAN\n",
        "latent_dim = 100\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Combined GAN model\n",
        "discriminator.trainable = False\n",
        "gan_input = layers.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 127.5 - 1  # Normalize to [-1, 1]\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# Training loop\n",
        "batch_size = 64\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train the discriminator\n",
        "    real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    fake_images = generator.predict(noise)\n",
        "    fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    valid_labels = np.ones((batch_size, 1))\n",
        "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
        "\n",
        "# Generate and display samples\n",
        "noise = np.random.normal(0, 1, (16, latent_dim))\n",
        "generated_images = generator.predict(noise)\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Explanation**:\n",
        "1. The generator creates fake images from random noise.\n",
        "2. The discriminator distinguishes between real and fake images.\n",
        "3. The GAN is trained in a competitive manner, with the generator improving over time.\n",
        "\n",
        "---\n",
        "\n",
        "### **8.4 Code Example: Building a VAE**\n",
        "Letâ€™s build a Variational Autoencoder (VAE) using TensorFlow/Keras to generate new images.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the encoder\n",
        "def build_encoder(latent_dim):\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "    x = layers.Flatten()(inputs)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "    return models.Model(inputs, [z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder\n",
        "def build_decoder(latent_dim):\n",
        "    inputs = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(256, activation='relu')(inputs)\n",
        "    x = layers.Dense(28 * 28, activation='sigmoid')(x)\n",
        "    outputs = layers.Reshape((28, 28, 1))(x)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# Define the VAE\n",
        "latent_dim = 2\n",
        "encoder = build_encoder(latent_dim)\n",
        "decoder = build_decoder(latent_dim)\n",
        "\n",
        "inputs = layers.Input(shape=(28, 28, 1))\n",
        "z_mean, z_log_var = encoder(inputs)\n",
        "\n",
        "# Reparameterization trick\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "outputs = decoder(z)\n",
        "vae = models.Model(inputs, outputs)\n",
        "\n",
        "# Define the VAE loss\n",
        "def vae_loss(inputs, outputs):\n",
        "    reconstruction_loss = tf.reduce_mean(tf.square(inputs - outputs))\n",
        "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "    return reconstruction_loss + kl_loss\n",
        "\n",
        "vae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0  # Normalize to [0, 1]\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# Train the VAE\n",
        "vae.fit(x_train, x_train, epochs=10, batch_size=128)\n",
        "\n",
        "# Generate and display samples\n",
        "n = 15\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "grid_x = np.linspace(-2, 2, n)\n",
        "grid_y = np.linspace(-2, 2, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Explanation**:\n",
        "1. The encoder maps input images to a latent space.\n",
        "2. The decoder generates images from the latent space.\n",
        "3. The VAE is trained to minimize both reconstruction loss and KL divergence.\n",
        "\n",
        "---\n",
        "\n",
        "### **8.5 Code Example: Diffusion Models**\n",
        "Letâ€™s use a pre-trained diffusion model from Hugging Face to generate images.\n",
        "\n",
        "```python\n",
        "from diffusers import DDPMPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained diffusion model\n",
        "pipeline = DDPMPipeline.from_pretrained('google/ddpm-cifar10-32')\n",
        "\n",
        "# Generate an image\n",
        "image = pipeline().images[0]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### **Explanation**:\n",
        "1. The diffusion model gradually adds noise to data and then reverses the process to generate new samples.\n",
        "2. The pre-trained model generates high-quality images.\n",
        "\n",
        "---\n",
        "\n",
        "### **8.6 In Conclusion**\n",
        "- Generative models create new data samples that resemble a given dataset.\n",
        "- GANs, VAEs, and diffusion models are popular types of generative models.\n",
        "- These models have applications in image synthesis, data augmentation, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab6aadd1",
      "metadata": {
        "id": "ab6aadd1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}