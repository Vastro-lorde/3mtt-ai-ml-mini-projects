{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66dec707",
   "metadata": {},
   "source": [
    "## Mini-Project Title: Building a Text Classification Model for News Categorization\n",
    "\n",
    "## Overview\n",
    "This project focuses on using Natural Language Processing (NLP) techniques to build a text classification model for news categorization. With a large influx of news articles daily, manual categorization is inefficient. Automating this process using NLP ensures scalability, accuracy, and consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb7f2b",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Develop an NLP-powered machine learning model that categorizes news articles into predefined categories such as Politics, Sports, Technology, Entertainment, and Health. This project covers the complete NLP pipeline, including preprocessing, feature extraction, model training, evaluation, and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c53fe0",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "1. Understand text preprocessing techniques like tokenization, stopword removal, and stemming/lemmatization.\n",
    "2. Explore feature extraction methods such as Bag of Words, TF-IDF, and word embeddings.\n",
    "3. Learn to use NLP libraries like NLTK, spaCy, and Hugging Face Transformers.\n",
    "4. Experiment with NLP-specific models such as LSTM, BERT, or other transformer-based models.\n",
    "5. Gain experience in deploying NLP models via APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff62da7",
   "metadata": {},
   "source": [
    "## Step 1: Define the Problem\n",
    "### Task:\n",
    "Understand the problem and its real-world implications. Automation of news categorization using NLP can save time, improve accuracy, and enhance user experience by organizing content effectively.\n",
    "\n",
    "### Mini-task:\n",
    "Write a brief paragraph on how NLP benefits the media industry in automating news categorization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab8d41",
   "metadata": {},
   "source": [
    "NLP (Natural Language Processing) greatly benefits the media industry by automating the categorization of news articles. This automation enables media organizations to efficiently process and organize vast amounts of content, ensuring that articles are accurately sorted into relevant categories such as Politics, Sports, Technology, and more. As a result, it saves time, reduces manual effort, minimizes human error, and enhances the user experience by making it easier for readers to find news that matches their interests. Additionally, automated categorization supports better content management and personalized recommendations, helping media companies stay competitive in the digital age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b787a8e",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection\n",
    "### Task:\n",
    "Collect a dataset of news articles suitable for text classification. Publicly available datasets such as the AG News dataset or datasets from Kaggle can be used.\n",
    "\n",
    "### Mini-task:\n",
    "Download and load a suitable dataset for NLP tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a7abb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download and load the AG News dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "# Display the first few samples\n",
    "print(dataset['train'][0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9134915",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis (EDA)\n",
    "### Task:\n",
    "Analyze the dataset to understand the text structure, class distribution, and any potential imbalances.\n",
    "\n",
    "### Mini-task:\n",
    "Visualize the class distribution using a bar chart and inspect a few examples of text data.\n",
    "\n",
    "Example\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert dataset to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Inspect a sample\n",
    "print(df.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d3dcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
      "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
      "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
      "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
      "4  Oil prices soar to all-time record, posing new...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert dataset to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Visualize class distribution\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Inspect a sample of the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9bab0",
   "metadata": {},
   "source": [
    "## Step 4: Text Preprocessing\n",
    "### Task:\n",
    "Preprocess the text data using techniques such as:\n",
    "- Lowercasing\n",
    "- Tokenization\n",
    "- Stopword removal\n",
    "- Lemmatization (optional)\n",
    "\n",
    "### Mini-task:\n",
    "Clean a small sample of the dataset using NLP libraries like NLTK or spaCy.\n",
    "\n",
    "Example\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess)\n",
    "print(df[['text', 'cleaned_text']].head())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c89534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1a50b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Wall St. Bears Claw Back Into the Black (Reute...   \n",
      "1  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
      "2  Oil and Economy Cloud Stocks' Outlook (Reuters...   \n",
      "3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
      "4  Oil prices soar to all-time record, posing new...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  wall st bears claw black reuter reuter short s...  \n",
      "1  carlyle look commercial aerospace reuter reute...  \n",
      "2  oil economy cloud stock outlook reuters reuter...  \n",
      "3  iraq halt oil export main southern pipeline re...  \n",
      "4  oil price soar time record pose new menace eco...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to a small sample\n",
    "df['cleaned_text'] = df['text'].apply(preprocess)\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1459554",
   "metadata": {},
   "source": [
    "### Step 5: Feature Engineering\n",
    "### Task:\n",
    "Convert the preprocessed text into numerical representations using:\n",
    "- Bag of Words (BoW)\n",
    "- Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "- Pre-trained word embeddings (e.g., GloVe or FastText)\n",
    "\n",
    "### Mini-task:\n",
    "Compare the feature matrices generated using TF-IDF and embeddings.\n",
    "\n",
    "Example\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Representation\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb9cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (120000, 5000)\n",
      "spaCy Embedding Matrix Shape: (120000, 96)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# TF-IDF Representation\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
    "\n",
    "# spaCy Embeddings (using the mean vector for each document)\n",
    "def get_embedding(text):\n",
    "    doc = nlp(text)\n",
    "    return doc.vector\n",
    "\n",
    "embeddings = np.vstack(df['cleaned_text'].apply(get_embedding))\n",
    "print(\"spaCy Embedding Matrix Shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23f187",
   "metadata": {},
   "source": [
    "## Step 6: Model Training Using NLP Models\n",
    "### Task:\n",
    "Train a machine learning model using features derived from NLP techniques. You can use classical models like Logistic Regression or advanced models like LSTMs or transformers.\n",
    "\n",
    "### Mini-task:\n",
    "Train a simple logistic regression model on the TF-IDF features.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646578b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 90.87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Accuracy\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d8060",
   "metadata": {},
   "source": [
    "### Optional: Fine-Tune a BERT Model\n",
    "Train a transformer-based model using the Hugging Face `transformers` library for state-of-the-art results in text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd19dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 120000/120000 [00:15<00:00, 7567.73 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='341' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  341/12000 19:44 < 11:18:44, 0.29 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.288900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.334600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.404900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:659] . unexpected pos 93788160 vs 93788048",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\torch\\serialization.py:965\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\torch\\serialization.py:1266\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1265\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:862] . PytorchStreamWriter failed writing file data/2: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     44\u001b[39m trainer = Trainer(\n\u001b[32m     45\u001b[39m     model=model,\n\u001b[32m     46\u001b[39m     args=training_args,\n\u001b[32m     47\u001b[39m     train_dataset=train_dataset,\n\u001b[32m     48\u001b[39m     eval_dataset=eval_dataset\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[32m     55\u001b[39m results = trainer.evaluate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\transformers\\trainer.py:2207\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2205\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\transformers\\trainer.py:2624\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2622\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2623\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2624\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2635\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\transformers\\trainer.py:3104\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3101\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3104\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3105\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\transformers\\trainer.py:3212\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3208\u001b[39m         \u001b[38;5;28mself\u001b[39m.state.best_model_checkpoint = best_checkpoint_dir\n\u001b[32m   3210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3211\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3212\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3213\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3214\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\transformers\\trainer.py:3339\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3334\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3335\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3336\u001b[39m     )\n\u001b[32m   3337\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3338\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3339\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3341\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3342\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3343\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3344\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\torch\\serialization.py:964\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    961\u001b[39m     f = os.fspath(f)\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    965\u001b[39m         _save(\n\u001b[32m    966\u001b[39m             obj,\n\u001b[32m    967\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m             _disable_byteorder_record,\n\u001b[32m    971\u001b[39m         )\n\u001b[32m    972\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\onuoh\\.virtualenvs\\3mtt-ai-ml-mini-projects-ViWCxpd9\\Lib\\site-packages\\torch\\serialization.py:798\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    800\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_stream.close()\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:659] . unexpected pos 93788160 vs 93788048"
     ]
    }
   ],
   "source": [
    "# Optional: Fine-Tune a BERT Model for Text Classification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Prepare the dataset for Hugging Face Transformers\n",
    "train_texts = df['text'].tolist()\n",
    "train_labels = df['label'].tolist()\n",
    "dataset_hf = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Split into train and test\n",
    "split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split['train']\n",
    "eval_dataset = split['test']\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(set(train_labels)))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=10\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"BERT Model Accuracy: {results['eval_accuracy']*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3mtt-ai-ml-mini-projects-ViWCxpd9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
